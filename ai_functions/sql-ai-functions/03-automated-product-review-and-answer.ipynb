{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f313768-88dd-45ad-a4ad-a435231a7144",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 3/ Automated product review and classification with SQL functions\n",
    "\n",
    "\n",
    "In this demo, we will explore the SQL AI function `ai_query` to create a pipeline extracting product review information.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/main/images/product/sql-ai-functions/sql-ai-query-function-flow.png\" width=\"1000\">\n",
    "\n",
    "**Don't forget about built-in SQL AI functions!** *In this notebook, we show you how to create your own custom functions. However, many text-related tasks (translation, classification etc.) are available as [builtin SQL functions]($./01-Builtin-SQL-AI-Functions). If you can, prefere these as they're easy to use and performant!*\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection or disable tracker during installation. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=DBSQL&org_id=984752964297111&notebook=%2F03-automated-product-review-and-answer&demo_name=sql-ai-functions&event=VIEW&path=%2F_dbdemos%2FDBSQL%2Fsql-ai-functions%2F03-automated-product-review-and-answer&version=1&user_hash=d0474b04fa5f647b58e56efa05dd4a6e679929fda0191106826e4a09d21dcede\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b495b08-69eb-4bdc-b742-d4e41d337ed1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "To run this notebook, connect to <b> SQL endpoint </b>. The AI_QUERY function is available on Databricks SQL Pro and Serverless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4ade300-2544-4a85-929a-c5023ee49391",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- as previously, make sure you run this notebook using a SQL Warehouse or Serverless endpoint (not a classic cluster)\n",
    "SELECT assert_true(current_version().dbsql_version is not null, 'YOU MUST USE A SQL WAREHOUSE OR SERVERLESS, not a classic cluster');\n",
    "\n",
    "USE CATALOG dbacademy;\n",
    "USE SCHEMA himanshu_gupta;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2847b60-0070-4697-903c-43eb7642c7cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Simplifying AI function access for SQL users\n",
    "\n",
    "As reminder, `ai_query` signature is the following:\n",
    "\n",
    "```\n",
    "SELECT ai_query(<Endpoint Name>, <prompt>)\n",
    "```\n",
    "\n",
    "In the [previous notebook]($./02-Generate-fake-data-with-AI-functions-Foundation-Model), we created a wrapper `ASK_LLM_MODEL` function to simplify our SQL operation and hide the configuration details to end-users. We will re-use this function for this pipeline.\n",
    "\n",
    "In order to simplify the user-experience for our analysts, we will build prescriptive SQL functions that ask natural language questions of our data and return the responses as structured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6438a9b-6137-404a-8209-836e2a06f4bb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Review our raw data"
    }
   },
   "outputs": [],
   "source": [
    "SELECT * FROM fake_reviews INNER JOIN fake_customers using (customer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb9fe05a-e48d-4f7b-8b48-e1ef27c59729",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Review analysis with prompt engineering \n",
    "&nbsp;\n",
    "The keys to getting useful results back from a LLM model are:\n",
    "- Asking it a well-formed question\n",
    "- Being specific about the type of answer that you are expecting\n",
    "\n",
    "In order to get results in a form that we can easily store in a table, we'll ask the model to return the result in a string that reflects `JSON` representation, and be very specific of the schema that we expect\n",
    "\n",
    "Here's the prompt we've settled on:\n",
    "```\n",
    "A customer left a review on a product. We want to follow up with anyone who appears unhappy.\n",
    "Extract all entities mentioned. For each entity:\n",
    "- classify sentiment as [\"POSITIVE\",\"NEUTRAL\",\"NEGATIVE\"]\n",
    "- whether customer requires a follow-up: Y or N\n",
    "- reason for requiring followup\n",
    "\n",
    "Return JSON ONLY. No other text outside the JSON. JSON format:\n",
    "[{\n",
    "    \"product_name\": <product name>,\n",
    "    \"category\": <product category>,\n",
    "    \"sentiment\": <review sentiment, one of [\"POSITIVE\",\"NEUTRAL\",\"NEGATIVE\"]>,\n",
    "    \"followup\": <Y or N for follow up>,\n",
    "    \"followup_reason\": <reason for followup>\n",
    "}]\n",
    "\n",
    "Review:\n",
    "<insert review text here>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "385ae634-399b-4819-9bb4-62c1aa6f13e1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create the ANNOTATE function"
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE FUNCTION ANNOTATE_REVIEW(review STRING)\n",
    "    RETURNS STRUCT<product_name: STRING, entity_sentiment: STRING, followup: STRING, followup_reason: STRING>\n",
    "    RETURN FROM_JSON(\n",
    "      ASK_LLM_MODEL(CONCAT(\n",
    "        'A customer left a review. We follow up with anyone who appears unhappy.\n",
    "         extract the following information:\n",
    "          - classify sentiment as [\"POSITIVE\",\"NEUTRAL\",\"NEGATIVE\"]\n",
    "          - returns whether customer requires a follow-up: Y or N\n",
    "          - if followup is required, explain what is the main reason\n",
    "\n",
    "        Return JSON ONLY. No other text outside the JSON. JSON format:\n",
    "        {\n",
    "            \"product_name\": <entity name>,\n",
    "            \"entity_sentiment\": <entity sentiment>,\n",
    "            \"followup\": <Y or N for follow up>,\n",
    "            \"followup_reason\": <reason for followup>\n",
    "        }\n",
    "        \n",
    "        Review:', review), \"{'type': 'json_object'}\"),\n",
    "      \"STRUCT<product_name: STRING, entity_sentiment: STRING, followup: STRING, followup_reason: STRING>\")\n",
    "\n",
    "-- ALTER FUNCTION ANNOTATE_REVIEW OWNER TO `your_principal`; -- for the demo only, make sure other users can access your function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52c18487-dd62-437e-8adb-ff35e42e0ab3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Extract information from all our reviews"
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE reviews_annotated as \n",
    "    SELECT * EXCEPT (review_annotated), review_annotated.* FROM (\n",
    "      SELECT *, ANNOTATE_REVIEW(review) AS review_annotated\n",
    "        FROM fake_reviews)\n",
    "    INNER JOIN fake_customers using (customer_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f410be1c-01d3-4e60-90e7-b277c5e9f37d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT * FROM reviews_annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c40a441-25cf-4804-aa60-c29a3cee860e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE FUNCTION GENERATE_RESPONSE(firstname STRING, lastname STRING, order_count INT, product_name STRING, reason STRING)\n",
    "  RETURNS STRING\n",
    "  RETURN ASK_LLM_MODEL(\n",
    "    CONCAT(\"Our customer named \", firstname, \" \", lastname, \" who ordered \", order_count, \" \", product_name, \" was unhappy about \", product_name, \"specifically due to \", reason, \". Provide an empathetic message I can send to my customer \n",
    "    including the offer to have a call with the relevant product manager to leave feedback. I want to win back their \n",
    "    favour and I do not want the customer to churn\"), \n",
    "    \"{'type': 'text'}\"\n",
    "  );\n",
    "-- ALTER FUNCTION GENERATE_RESPONSE OWNER TO `account users`; -- for the demo only, make sure other users can access your function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3dde423a-473f-410e-ba5e-41b1768bcab0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT GENERATE_RESPONSE(\"Quentin\", \"Ambard\", 235, \"Country Choice Snacking Cookies\", \"Quality issue\") AS customer_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6777ade1-a3d4-4e90-a904-aeab94ae45bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE reviews_answer as \n",
    "    SELECT *,\n",
    "      generate_response(firstname, lastname, order_count, product_name, followup_reason) AS response_draft\n",
    "    FROM reviews_annotated where followup='Y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20f69c82-54fe-4bf2-9e49-01c70db6ea49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT * FROM reviews_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddfb816e-91e8-4389-aeae-71327da5e66e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Creating our Customer Review Dashboard\n",
    "\n",
    "The next step is to set up a comprehensive dashboard in order to track and monitor our customer reviews.\n",
    "\n",
    "Open the <a dbdemos-dashboard-id=\"customer-review-analysis\" href='/sql/dashboardsv3/01f0fd69937a17a3a48d8439d7c87a7f' target=\"_blank\">Customer review analysis dashboard</a> to have a complete view of your customers, products and reviews.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/main/images/product/sql-ai-functions/sql-ai-function-dashboard.png\" width=\"1200\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc5ad2b9-ff5d-47ac-8f8c-feb2ee0be8fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Going further\n",
    "\n",
    "Our pipeline is ready. Keep in mind that this is a fairly basic pipeline for our demo.\n",
    "\n",
    "For more advanced pipeline, we recommend using Spark Declarative Pipelines. SDP simplify data ingetsion and transformation tasks with incremental load, materialized view and more advanced features. For more details, run `dbdemos.install_demo('pipeline-bike')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ae3e01b-3c9d-465f-a0dd-fdf92d92d072",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Extra: AdHoc Queries\n",
    "\n",
    "Remember that analysts can always use the `ASK_LLM_MODEL()` function we created earlier to apply their own prompts to the data.\n",
    "\n",
    "As short example, let's write a query to extract all review about beverages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29a6cda8-c0aa-466a-8542-7c4796fc7b9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT review_id,\n",
    "    BOOLEAN(ASK_LLM_MODEL(\n",
    "      CONCAT(\"Does this review discuss beverages? Answer boolean: 'true' or 'false' only, lowercase, no explanations or notes nor final dot. Review: \", review)\n",
    "    )) AS is_beverage_review,\n",
    "    review\n",
    "  FROM fake_reviews LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "182e1883-7182-49cf-bc6a-99d434931374",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Extra: Create an Production Ready Pipeline using Spark Declarative Pipelines\n",
    "\n",
    "We can turn the steps in this notebook into a production ready Spark Declarative Pipelines pipeline with AI SQL Functions\n",
    "\n",
    "Open [04-create-end-to-end-DLT-workflow]($./04-create-end-to-end-DLT-workflow) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8460a4e-885e-4612-a0b3-f519aa336765",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## You're now ready to process your text using external LLM models!\n",
    "\n",
    "We've seen that the lakehouse provide advanced AI capabilities, not only you can leverage external LLM APIs, but you can also build your own LLM with Databricks GenAI applications!\n",
    "For more details on creating your chatbot with the Lakehouse, run: `dbdemos.install('llm-rag-chatbot')`\n",
    "\n",
    "Go back to [the introduction]($./01-SQL-AI-Functions-Introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e396c268-6c59-41fa-8751-b6e2e1bdb17c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Extra: configure an External Model Endpoint to leverage external providers (OpenAI, Anthropic...) \n",
    "\n",
    "This demo was using one Databricks Foundation Model (pricing token-based).\n",
    "\n",
    "Your model endpoint can also be setup to use an external model such as OpenAI. Open [05-Extra-setup-external-model-OpenAI]($./05-Extra-setup-external-model-OpenAI) for more details.\n",
    "\n",
    "\n",
    "Go back to [the introduction]($./00-SQL-AI-Functions-Introduction)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "03-automated-product-review-and-answer",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
