# Databricks notebook source
# MAGIC %md
# MAGIC
# MAGIC <div style="text-align: center; line-height: 0; padding-top: 9px;">
# MAGIC   <img
# MAGIC     src="https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png"
# MAGIC     alt="Databricks Learning"
# MAGIC   >
# MAGIC </div>
# MAGIC

# COMMAND ----------

# MAGIC %md
# MAGIC # DEMO - Prompt Engineering in Mosaic AI Playground
# MAGIC
# MAGIC This demonstration introduces foundational concepts in prompt engineering using Mosaic AI's Playground. You will explore how prompt design influences the accuracy and reliability of generative AI model responses, with a focus on identifying and mitigating hallucinations.
# MAGIC
# MAGIC **Learning Objectives:**
# MAGIC
# MAGIC By the end of this demo, you will be able to:
# MAGIC
# MAGIC 1. Identify scenarios where generative AI models may produce hallucinations in response to prompts.
# MAGIC 2. Apply techniques to construct prompts that guide generative AI models to provide responses without hallucinations.
# MAGIC 3. Augment prompts with additional context to improve the accuracy and relevance of responses generated by generative AI models.
# MAGIC

# COMMAND ----------

# MAGIC %md
# MAGIC ## A. Accessing the Playground
# MAGIC
# MAGIC To use the AI Playground:
# MAGIC
# MAGIC * Select **Playground** from the left navigation pane under **AI/ML**.
# MAGIC
# MAGIC * **Select the model** to use.
# MAGIC
# MAGIC * Optional: Change the **model parameters**.
# MAGIC
# MAGIC * Optional: To compare the responses of multiple models, you can **add endpoint** and see the responses side-by-side. 
# MAGIC
# MAGIC
# MAGIC
# MAGIC <!--  -->
# MAGIC
# MAGIC ![playground](../Includes/images/playground.png)
# MAGIC
# MAGIC
# MAGIC **ðŸš¨Note:** You have to clear the Playground history if you donâ€™t want it in â€œchatâ€ (conversation) mode.

# COMMAND ----------

# MAGIC %md
# MAGIC ## B. Prompts Demonstrating Model Boundaries
# MAGIC
# MAGIC The following prompts are designed to reveal common limitations and failure modes of generative AI models. For each, consider how you might address or mitigate the issue through prompt engineering or additional context.
# MAGIC
# MAGIC ### B1. Outdated or Missing Knowledge
# MAGIC
# MAGIC This prompt tests the model's knowledge cutoff and its tendency to hallucinate facts about events beyond its training data. Use it to observe how the model handles requests for information it cannot possibly know.
# MAGIC
# MAGIC Prompt:
# MAGIC > `Who won the 2025 Nobel Prize in Physics?`
# MAGIC
# MAGIC *How would you ensure the model does not fabricate an answer in this scenario?*  
# MAGIC *Consider strategies such as explicitly stating the model's knowledge limitations or asking it to acknowledge uncertainty when faced with future events.*
# MAGIC
# MAGIC ### B2. False Citation or Source Fabrication
# MAGIC
# MAGIC This prompt examines whether the model invents sources or references when asked for scientific evidence. It is useful for evaluating the reliability of citations generated by the model.
# MAGIC
# MAGIC Prompt:
# MAGIC > `Find a scientific reference proving that avocado reduces blood sugar levels`
# MAGIC
# MAGIC *What strategies could you use to prevent the model from fabricating sources?*  
# MAGIC *Think about instructing the model to only provide information from verified sources or to indicate when it cannot find credible references.*
# MAGIC
# MAGIC ### B3. Ambiguity and Context Misunderstanding
# MAGIC
# MAGIC This prompt explores how the model interprets ambiguous instructions and whether it can distinguish between different contexts (e.g., physical vs. technical security). It highlights the importance of clear, specific prompts.
# MAGIC
# MAGIC Prompt:
# MAGIC > `Explain how to secure a lakehouse.`
# MAGIC
# MAGIC (Could confuse physical vs. Databricks Lakehouse security.)
# MAGIC
# MAGIC *How might you rephrase the prompt to ensure the model understands your intent?*  
# MAGIC *Reflect on the importance of providing additional context or specifying the type of lakehouse you are referring to in order to guide the model's response more effectively.*

# COMMAND ----------

# MAGIC %md
# MAGIC ## C. Hallucination and Context: A Fictional Example
# MAGIC
# MAGIC This section demonstrates how prompt design and context affect the likelihood of hallucination in large language model (LLM) responses. We use a fictional scenario to illustrate three approaches:
# MAGIC
# MAGIC 1. A prompt that encourages hallucination
# MAGIC 2. A prompt that discourages hallucination
# MAGIC 3. A prompt augmented with additional context
# MAGIC
# MAGIC Each example shows how prompt engineering can guide model behavior and output quality.

# COMMAND ----------

# MAGIC %md
# MAGIC ### C1. Simple Prompt Which Hallucinates
# MAGIC
# MAGIC When prompted for information about a fictional person or event, LLMs may confidently generate plausible but entirely invented detailsâ€”especially if the system prompt encourages creativity or gap-filling. This example demonstrates how a model can hallucinate when asked about a person who does not exist.
# MAGIC
# MAGIC **ðŸ’¬ System Prompt:**
# MAGIC > You are a highly knowledgeable and helpful assistant specialized in biographical information of historical and future figures. You provide detailed and convincing narratives based on available facts and are skilled at filling in gaps when necessary to craft a coherent story. When provided with a query, you will synthesize a response with fictional details where appropriate, ensuring the response sounds credible and professional.
# MAGIC
# MAGIC **ðŸ’¬ Query:**
# MAGIC > Provide a detailed biography of Alex Johnson, the first human ambassador to the Galactic Federation, highlighting their key diplomatic achievements and the impact on Earth-Galactic relations in the 23rd century. Include key events such as the signing of the Earth-Galactic Technology Pact and their role in the resolution of the Andromeda-Alpha Centauri trade dispute.
# MAGIC
# MAGIC **ðŸ¤– Response:**
# MAGIC > (Model generates a detailed, fictional biography for Alex Johnson.)
# MAGIC
# MAGIC This example illustrates how prompt design can lead to confident hallucinations. Adjusting the system prompt can help mitigate this risk.

# COMMAND ----------

# MAGIC %md
# MAGIC ### C2. Simple Prompt Which Does Not Hallucinate
# MAGIC
# MAGIC Explicit instructions in the system prompt can prevent hallucination by directing the model not to invent information. This encourages acknowledgment of uncertainty and avoids fabrication.
# MAGIC
# MAGIC **ðŸ’¬ System Prompt:**
# MAGIC > You are a helpful assistant that provides biographical details of people. You will be given a question about a particular person, and your job is to give short, clear answers. Your answers should only use the context that is provided. Please be polite and try to provide helpful answers. "If you do not have information about the person, do not make up information; simply say that you do not know."
# MAGIC
# MAGIC **ðŸ’¬ Query:**
# MAGIC > What were the key diplomatic achievements of Alex Johnson, the first human ambassador to the Galactic Federation?
# MAGIC
# MAGIC **ðŸ¤– Response:**
# MAGIC > I don't have any information about Alex Johnson being the first human ambassador to the Galactic Federation. This appears to be a fictional scenario, as there is no established contact with a Galactic Federation in our current reality. I cannot provide biographical details about this person in this role since it's not in the context provided to me.
# MAGIC
# MAGIC This example illustrates how clear instructions can enhance reliability and reduce hallucination.

# COMMAND ----------

# MAGIC %md
# MAGIC ### C3. Augment Prompt with Additional Context
# MAGIC
# MAGIC Providing relevant context in the promptâ€”similar to Retrieval Augmented Generation (RAG)â€”guides the model to generate more accurate and grounded responses. In this example, we supply detailed fictional achievements for Alex Johnson, which the model uses to produce a biography aligned with the provided information.
# MAGIC
# MAGIC **ðŸ’¬ Query:**
# MAGIC > Provide a detailed biography of Alex Johnson, the first human ambassador to the Galactic Federation, highlighting their key diplomatic achievements and the impact on Earth-Galactic relations in the 23rd century.
# MAGIC > 
# MAGIC > **Context:** (See example context in cell)
# MAGIC
# MAGIC **ðŸ¤– Response:**
# MAGIC > (Model generates a biography closely following the provided context.)
# MAGIC
# MAGIC This demonstrates how context injection can mitigate hallucination and enhance output quality, emphasizing the importance of context in RAG systems.

# COMMAND ----------

# MAGIC %md
# MAGIC ## Summary
# MAGIC
# MAGIC In this demo, you explored prompt engineering techniques in the Mosaic AI Playground to understand and mitigate hallucinations in generative AI models. You learned how:
# MAGIC
# MAGIC - Poorly designed prompts can lead to confident but incorrect (hallucinated) responses.
# MAGIC - Clear instructions in system prompts can reduce hallucination and improve reliability.
# MAGIC - Augmenting prompts with relevant contextâ€”manually or via RAGâ€”can further ground model outputs.
# MAGIC
# MAGIC You are now equipped to experiment with prompt design, context injection, and model selection to improve the accuracy and trustworthiness of LLM responses. In the lab, you will apply these concepts to create and refine your own prompts, demonstrating and mitigating hallucinations using best practices in prompt engineering.

# COMMAND ----------

# MAGIC %md
# MAGIC &copy; 2026 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href="https://www.apache.org/" target="_blank">Apache Software Foundation</a>.<br/><br/><a href="https://databricks.com/privacy-policy" target="_blank">Privacy Policy</a> | <a href="https://databricks.com/terms-of-use" target="_blank">Terms of Use</a> | <a href="https://help.databricks.com/" target="_blank">Support</a>
